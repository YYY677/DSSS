{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huanfachen/DSSS/blob/main/Week_5/Practical_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umCFkGTqxMge"
      },
      "source": [
        "<div style=\"float:left\">\n",
        "    <h1 style=\"width:600px\">CASA0006 Practical 5: Neural networks using tensorflow</h1>\n",
        "</div>\n",
        "<div style=\"float:right\"><img width=\"100\" src=\"https://github.com/jreades/i2p/raw/master/img/casa_logo.jpg\" /></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04QgGZc9bF5D"
      },
      "source": [
        "## Introduction\n",
        "In this practical, we will introduce [Tensorflow](https://www.tensorflow.org/guide/keras/overview) and use it to:\n",
        "\n",
        "1. Build a simple two-layer neural network for digit recognition;\n",
        "1. Train and evaluate this neural network;\n",
        "\n",
        "## Setting up Google Colab\n",
        "\n",
        "As installing and configuring tensorflow on laptop can be a pain, we recommend using Google Colab for this practical. Click [here](https://colab.research.google.com/github/huanfachen/DSSS/blob/main/Week_5/Practical_05.ipynb) to run this practical on Google Colab, which requires a Google account.\n",
        "\n",
        "Resource limit of Google Colab under free plan:\n",
        "\n",
        "- Memory: up to 12 GB.\n",
        "- Maximum duration of running a notebook: notebooks can run for at most **12 hours**, depending on availability and your usage patterns. (The notebook will die after at most 12 hours)\n",
        "- GPU duration: dynamic, up to a few hours. If you use GPU regularly, runtime durations will become shorter and shorter and disconnections more frequent.\n",
        "\n",
        "*Very Important* - we will use the GPU on Google Colab to accelerate the model training. To do this, go to 'Runtime' -> 'Change runtime type' -> Select 'T4 GPU' -> Save. See below.\n",
        "\n",
        "![](https://github.com/huanfachen/DSSS/blob/main/Figures/Colab_GPU_setting.jpg?raw=true)\n",
        "\n",
        "If you are following along in your own development environment, rather than Colab, see the [install guide](https://www.tensorflow.org/install) for setting up TensorFlow for development.\n",
        "\n",
        "Note: if you are using your own development environment, please make sure you have upgraded to the latest `pip` before installing TensorFlow 2 package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview of TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[TensorFlow](https://www.tensorflow.org/) is an open source library developed by Google for numerical computation. It is particularly well suited for large-scale machine learning.    \n",
        "\n",
        "TensorFlow is based on the construction of *computational graphs*. It has evolved considerably since it's open source release in 2015.  We will use TF2, which offers many additional features built on top of core features (the most important is `tf.keras` discussed in later lectures)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Features of TF\n",
        "\n",
        "- Similar to [`numpy`](https://numpy.org/doc/stable/) but with GPU support.\n",
        "- Supports distributed computing.\n",
        "- Includes a kind of just-in-time (JIT) compiler to optimise speed and memory usage.\n",
        "- Computational graphs can be saved and exported.\n",
        "- Supports autodiff and provides numerous advanced optimisers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TensorFlow's Python API\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/huanfachen/DSSS/main/Figures/tensorflow-Python-API.png\" width=\"700px\" style=\"display:block; margin:auto\"/>\n",
        "\n",
        "[Credit: Geron]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TensorFlow's Architecture\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/huanfachen/DSSS/main/Figures/tensorflow-Architecture.png\" width=\"700px\" style=\"display:block; margin:auto\"/>\n",
        "\n",
        "[Credit: Geron]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At lowest level TensorFlow is implemented in C++ so that it is highly efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will focus on the python TensorFlow and Keras interfaces in this practical. \n",
        "\n",
        "In real-world projects, if you use tensorflow, you will simply interact with the Keras interface but sometimes you might want to use the low-level python API for greater flexibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hardware"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One of the factors responsible for the dramatic recent growth of machine learning is advances in computing power.  \n",
        "\n",
        "In particular, hardware that supports high levels of parallelism."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/huanfachen/DSSS/main/Figures/cpu_gpu_tpu.png\" width=\"750px\" style=\"display:block; margin:auto\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Central Processing Unit (CPU):\n",
        "  - General purpose\n",
        "  - Low latency\n",
        "  - Low throughput\n",
        "  - Sequential\n",
        "  \n",
        "- Graphics Processing Unit (GPU)\n",
        "  - Specialised (for graphics initially)\n",
        "  - High latency\n",
        "  - High throughput\n",
        "  - Parallel execution\n",
        "  \n",
        "- Tensor Processing Unit (TPU)\n",
        "  - Specialised for matrix operations\n",
        "  - High latency\n",
        "  - Very high throughput\n",
        "  - Extreme parallel execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In TensorFlow many operations are implemented in low-level kernels, optimised for specific hardware, e.g. CPUs, GPUS, or TPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TensorFlow's execution engine will ensure operations are run efficiently (across multiple machines and devices if set up accordingly)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://raw.githubusercontent.com/astro-informatics/course_mlbd_images/master/Lecture11_Images/tensorflow-Architecture.png\" width=\"700px\" style=\"display:block; margin:auto\"/>\n",
        "\n",
        "[Credit: Geron]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Aside: chips optimised for ML and AI are an active area of development\n",
        "\n",
        "Key events of GPU:\n",
        "- 1999: NVIDIA released GeForce 256 (the first GPU), originally for gaming tasks;\n",
        "- 2007: NVIDIA released CUDA (**Computing Unified Device Architecture**), a software layer that allows software to use the powerful processing capabilities of GPUs to perform tasks much faster, including AI and gaming;\n",
        "- 2022: OpenAI launched ChatGPT, which was trained on thousands of Nvidia A100 and H100 GPUs.\n",
        "\n",
        "Google developed TPU in 2016.\n",
        "\n",
        "[Graphcore](https://www.graphcore.ai/) developed the Intelligence Processing Unit (IPU) in 2016.\n",
        "\n",
        "[Groq](https://www.groq.com/) developed the Language Processing Unit (LPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "******************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnrWf3PCEzXL"
      },
      "source": [
        "## Set up TensorFlow\n",
        "\n",
        "Import TensorFlow into your programme to get started:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow version:\", tf.??)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key data type: tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TensorFlow API centers around \"Tensors\" (essentially multi-dimensional arrays of matrices), which are similar to numpy [`ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can construct constant tensors with `tf.constant`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # 2x3 matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.constant(42) # scalar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tensors have a shape and data type (dtype)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
        "t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tensor indexing is very similar to numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t[..., 1,  tf.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Variety of tensor operations are possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# square\n",
        "tf.square(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# matrix multiplication\n",
        "t @ tf.transpose(t) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tensors and numpy ndarray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tensors and ndarray are highly compatible. Can create a tensor from ndarray."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = np.array([2., 4., 5.])\n",
        "tf.constant(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can convert tensor to ndarray."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Can apply numpy operations to tensors and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.array(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.square(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.square(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notes: the section of 'gradients' is optional. If you don't understand it, it is fine.\n",
        "\n",
        "When training neural networks using gradient descent based approaches, we often need to compute the gradients, in particular, we need to compute the gradient of the cost function with respect to the model weights.  \n",
        "\n",
        "TensorFlow supports automatical differentiation, which allows gradients to be computed automatically. We will compute gradients analytically, numerically and using TensorFlow's Autodiff functionality at the following point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider this function $ f(w_1, w_2) $ is defined as:\n",
        "\n",
        "$$\n",
        "f(w_1, w_2) = 3w_1^2 + 2w_1w_2\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(w1, w2):\n",
        "    return 3 * w1 ** 2 + 2 * w1 * w2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# example of w1 and w2\n",
        "w1, w2 = 5.0, 3.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing gradients analytically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def df_dw1(w1, w2):\n",
        "    return 6 * w1 + 2 * w2\n",
        "def df_dw2(w1, w2):\n",
        "    return 2 * w1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_dw1(w1, w2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_dw2(w1, w2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we compute the gradient analytically, we would need an extra function evaluation for every gradient.  Computationally infeasible for many cases, e.g. large neural networks with hundreds of thousands or millions of parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing gradients numerically\n",
        "\n",
        "Compute the gradient by finite differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eps = 1e-6\n",
        "(f(w1 + eps, w2) - f(w1, w2)) / eps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(f(w1, w2 + eps) - f(w1, w2)) / eps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note - the gradients computed numerically are approximate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing gradients with Autodiff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Autodiff builds derivatives of each stage of the computational graph so that gradients can be computed automatically and efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "    z = f(w1, w2)\n",
        "\n",
        "gradients = tape.gradient(z, [w1, w2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computing gradients with Autodiff only requires one computation, regardless of how many derivatives need to be computed. The results do not suffer from any numerical approximations, although it is limited by machine precision arithmetic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building a simple neural network using TF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will build a 2-hidden layers fully connected neural network (a.k.a multilayer perceptron) with TF. This example uses a low-level approach to better understand all mechanics behind building neural networks and the training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Neural Network Overview\n",
        "\n",
        "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n",
        "\n",
        "### MNIST Dataset Overview\n",
        "\n",
        "We will train the neural network to identify MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 255. \n",
        "\n",
        "In this example, each image will be converted to float32, normalized to [0, 1] and flattened to a 1-D array of 784 features (28*28).\n",
        "\n",
        "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
        "\n",
        "More info: http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MNIST dataset parameters.\n",
        "num_classes = 10 # total classes (0-9 digits).\n",
        "num_feature_one_dimension = 28 # img shape: 28*28\n",
        "\n",
        "# Training parameters.\n",
        "# learning_rate = 0.1\n",
        "# training_steps = 2000\n",
        "# batch_size = 256\n",
        "# display_step = 100\n",
        "\n",
        "# Network parameters.\n",
        "n_hidden_1 = 128 # 1st layer number of neurons.\n",
        "n_hidden_2 = 256 # 2nd layer number of neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "## Load a dataset\n",
        "\n",
        "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Convert the sample data from integers to floating-point numbers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FP5258xjs-v",
        "outputId": "259c6ef7-1353-4e37-9bd9-ebb510719747"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# normalisation - convert the sample data (range of 1-125) to floating numbers\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TdPgRJrUGhCA",
        "outputId": "004c7060-0ba5-4016-f87c-ccdcad7f0a2b"
      },
      "outputs": [],
      "source": [
        "# function for visualising digits\n",
        "def plot_num(number):\n",
        "\n",
        "  item_index = np.where(y_train[:1000]==number)\n",
        "  subset=x_train[item_index]\n",
        "\n",
        "  egs=5\n",
        "  fig, axs = plt.subplots(1,egs, figsize=(20,10))\n",
        "\n",
        "  for i in range(0,egs):\n",
        "    axs[i].imshow(subset[i])\n",
        "\n",
        "for x in range(0,10):\n",
        "  plot_num(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "## Build a machine learning model\n",
        "\n",
        "Build a `tf.keras.Sequential` model by stacking layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  # input layer (28*28), which is flattened before being fed into the neural network\n",
        "  tf.keras.layers.Flatten(input_shape=(num_feature_one_dimension, num_feature_one_dimension)),\n",
        "  # First fully-connected hidden layer.\n",
        "  tf.keras.layers.Dense(n_hidden_1, activation='relu'),\n",
        "  # Second fully-connected hidden layer.\n",
        "  tf.keras.layers.Dense(??, activation='relu'),\n",
        "  # output layer\n",
        "  tf.keras.layers.Dense(??)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2hiez2eIUz8"
      },
      "source": [
        "For each example, the model returns a vector of [logits](https://developers.google.com/machine-learning/glossary#logits) or [log-odds](https://developers.google.com/machine-learning/glossary#log-odds) scores, one for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeOrNdnkEEcR",
        "outputId": "b38f7eaa-1db8-4657-ad9f-5798d59123b4"
      },
      "outputs": [],
      "source": [
        "predictions = model(x_train[:1]).numpy()\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgjhDQGcIniO"
      },
      "source": [
        "The `tf.nn.softmax` function converts these logits to *probabilities* for each class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWSRnQ0WI5eq",
        "outputId": "bc6214b1-850c-427e-eba0-a52a134a4997"
      },
      "outputs": [],
      "source": [
        "tf.nn.softmax(predictions).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he5u_okAYS4a"
      },
      "source": [
        "Note: It is possible to bake the `tf.nn.softmax` function into the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it's impossible to provide an exact and numerically stable loss calculation for all models when using a softmax output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQyugpgRIyrA"
      },
      "source": [
        "Define a loss function for training using `losses.SparseCategoricalCrossentropy`, which takes a vector of logits and a `True` index and returns a scalar loss for each example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSkzdv8MD0tT"
      },
      "outputs": [],
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfR4MsSDU880"
      },
      "source": [
        "This loss is equal to the negative log probability of the true class: The loss is zero if the model is sure of the correct class.\n",
        "\n",
        "This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to `-tf.math.log(1/10) ~= 2.3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJWqEVrrJ7ZB",
        "outputId": "aed3cdea-1e67-460c-e2a4-a24b7e4027a5"
      },
      "outputs": [],
      "source": [
        "loss_fn(y_train[:1], predictions).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ada44eb947d4"
      },
      "source": [
        "Before you start training, configure and compile the model using Keras `Model.compile`. Set the [`optimizer`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) class to `adam`, set the `loss` to the `loss_fn` function you defined earlier, and specify a metric to be evaluated for the model by setting the `metrics` parameter to `accuracy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9foNKHzTD2Vo"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4mEL65on-w"
      },
      "source": [
        "## Train and evaluate your model\n",
        "\n",
        "Use the `Model.fit` method to adjust your model parameters and minimise the loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7suUbJXVLqP",
        "outputId": "0939186d-be56-4367-b386-322d05903ee8"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, ??, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mDAAPFqVVgn"
      },
      "source": [
        "The `Model.evaluate` method checks the models performance, usually on a [Validation set](https://developers.google.com/machine-learning/glossary#validation-set) or [Test set](https://developers.google.com/machine-learning/glossary#test-set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7dTAzgHDUh7",
        "outputId": "5c539d3d-b5d2-4d14-8d61-d47e120d9b5c"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test,  ??, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4JfEh7kvx6m"
      },
      "source": [
        "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj8NrlzlJqDG"
      },
      "source": [
        "If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYb6DrEH0GMv"
      },
      "outputs": [],
      "source": [
        "probability_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.Softmax()\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To check a random data point and prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "cnqOZtUp1YR_",
        "outputId": "ce7851b0-2cf4-40cd-cf0c-247ac0a454e4"
      },
      "outputs": [],
      "source": [
        "#probability_model(x_test[:1])\n",
        "predictions=probability_model.predict(x_test)\n",
        "\n",
        "index=20\n",
        "\n",
        "print(np.argmax(predictions[index]))\n",
        "plt.imshow(x_test[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-47O6_GLdRuT"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Congratulations! You have trained a machine learning model using a prebuilt dataset using the [Keras](https://www.tensorflow.org/guide/keras/overview) API.\n",
        "\n",
        "For more examples of using Keras, check out the [tutorials](https://www.tensorflow.org/tutorials/keras/). To learn more about building models with Keras, read the [guides](https://www.tensorflow.org/guide/keras). If you want learn more about loading and preparing data, see the tutorials on [image data loading](https://www.tensorflow.org/tutorials/load_data/images) or [CSV data loading](https://www.tensorflow.org/tutorials/load_data/csv).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References and recommendations:\n",
        "\n",
        "1. Some materials are from Machine Learning with Big Data (SPCE0038) module at UCL."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "name": "MachineLearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "d0d2e6730a6c54b05bb0156bc757d1580bef729e038830e8c9d99016e96c4534"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
